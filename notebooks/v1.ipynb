{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(paths: list[str]) -> str:\n",
    "    \"\"\"Load the contents of a file and return it as a string\"\"\"\n",
    "    for path in paths:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            yield f.read()\n",
    "\n",
    "def extract_variables(prompt: str, opening=\"{\", closing=\"}\") -> list[str]:\n",
    "    \"\"\"Extract and return variables encolsed in specific delimeters from the given prompt string.\"\"\"\n",
    "    variables = []\n",
    "    inside_braces = False\n",
    "    current_variable = []\n",
    "    \n",
    "    for char in prompt:\n",
    "        if char == opening:\n",
    "            inside_braces = True\n",
    "            current_variable = []\n",
    "            \n",
    "        elif char == closing:\n",
    "            if current_variable and inside_braces:\n",
    "                variables.append(''.join(current_variable))\n",
    "            inside_braces = False\n",
    "        elif inside_braces:    \n",
    "            current_variable.append(char)\n",
    "            \n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENum \n",
    "from enum import Enum\n",
    "   \n",
    "class Dimension(str, Enum):\n",
    "    UNDERSTANDING = \"Understanding of the problem\"\n",
    "    PROBLEM_SOLVING = \"Problem-solving approach\"\n",
    "    CODE_QUALITY = \"Code efficiency and cleanliness\"\n",
    "    COMMUNICATION = \"Communication skills\"\n",
    "    TIME_MANAGEMENT = \"Time management\"\n",
    "    \n",
    "class EvaluationModel(BaseModel):\n",
    "    \"\"\"Model for the evaluation of the user's response.\"\"\"\n",
    "    dimension: Dimension = Field(description=\"The dimension being evaluated. One of the following: Understanding of the problem, Problem-solving approach, Code efficiency and cleanliness, Communication skills, Time management.\")\n",
    "    score: float = Field(description=\"The score of the user's response from 100.\")\n",
    "    feedback: str = Field(description=\"The feedback for the user's response. Concise and evidence based.\")\n",
    "\n",
    "\n",
    "class InterviewModel(BaseModel):\n",
    "    end: bool = Field(description=\"Whether the interview has ended.\")\n",
    "    response: str = Field(description=\"The response from the interviewer that will be spoken out to the user.\")\n",
    "\n",
    "    evaluation: list[EvaluationModel] = Field(description=\"List of evaluations. This should be returned only when the interview has ended.\", default=[])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "\t SYSTEM: ['problem', 'time_allotted']\n",
      "\t USER: ['user_input', 'code_snapshot', 'time_elapsed'] \n"
     ]
    }
   ],
   "source": [
    "system_prompt, user_prompt = load_txt([\"system_prompt.txt\", \"user_prompt.txt\"])\n",
    "print(f\"Variables:\\n\\t SYSTEM: {extract_variables(system_prompt)}\\n\\t USER: {extract_variables(user_prompt)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=InterviewModel)\n",
    "\n",
    "interviewer_template = PromptTemplate(\n",
    "        template= system_prompt + \"\\n\\n Chat History: {chat_history}\\n\\n\" + \"\\n\\n  {format_instructions} \\n\\n\" + user_prompt,\n",
    "        input_variables=[\"problem\", \"time_allotted\", \"user_input\", \"code_snapshot\", \"time_elapsed\", \"chat_history\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_chain = interviewer_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\"\n",
    "27. Remove Element (Easy)\n",
    "\n",
    "Given an integer array nums and an integer val, remove all occurrences of val in nums in-place. The order of the elements may be changed. Then return the number of elements in nums which are not equal to val.\n",
    "\n",
    "Consider the number of elements in nums which are not equal to val be k, to get accepted, you need to do the following things:\n",
    "\n",
    "Change the array nums such that the first k elements of nums contain the elements which are not equal to val. The remaining elements of nums are not important as well as the size of nums.\n",
    "Return k.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the DSA Interview Simulator!\n",
      "AI: end=True response=\"Thank you for your time, Munim! We have reached the end of our interview. Let's go over your performance. You demonstrated a good understanding of the problem requirements and outlined a clear approach to solving it. Your method of using a counter and iterating through the array was solid. However, you could enhance your approach by detailing how to efficiently shift elements in place. Your communication was clear throughout the interview, but make sure to keep your answers concise. Overall, I would rate your understanding of the problem at eighty-five out of one hundred. Your problem-solving approach also scores eighty-five, while your code efficiency and cleanliness could be improved, so I would give that a seventy-five. Communication skills were strong, scoring ninety, and your time management was fair, scoring seventy. Keep practicing, and I wish you the best in your future endeavors!\" evaluation=[EvaluationModel(dimension=<Dimension.UNDERSTANDING: 'Understanding of the problem'>, score=85.0, feedback='You clearly understood the problem requirements, but could elaborate on the in-place modifications.'), EvaluationModel(dimension=<Dimension.PROBLEM_SOLVING: 'Problem-solving approach'>, score=85.0, feedback='Your approach was logical, but more detail on element shifting would strengthen it.'), EvaluationModel(dimension=<Dimension.CODE_QUALITY: 'Code efficiency and cleanliness'>, score=75.0, feedback='While your approach was sound, ensure your code is optimized for clarity and efficiency.'), EvaluationModel(dimension=<Dimension.COMMUNICATION: 'Communication skills'>, score=90.0, feedback='You communicated your thoughts well, making it easy to follow your reasoning.'), EvaluationModel(dimension=<Dimension.TIME_MANAGEMENT: 'Time management'>, score=70.0, feedback='You spent too much time on the initial outline; try to balance planning and implementation.')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f2c922428142c2b2d115c618645a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Textarea(value='', description='Message:', layout=Layout(height='100px', width='100%'), placehoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Provided variables\n",
    "time_allotted = 40\n",
    "user_input = None\n",
    "code_snapshot = None\n",
    "time_elapsed = None\n",
    "i = 0\n",
    "\n",
    "# Provided print statement\n",
    "print(\"Welcome to the DSA Interview Simulator!\")\n",
    "\n",
    "# Function to handle interaction in Jupyter Notebook\n",
    "def handle_interaction(submit_btn):\n",
    "    global user_input, code_snapshot, time_elapsed, i\n",
    "    \n",
    "    # Update the time elapsed\n",
    "    time_elapsed = i * 10\n",
    "\n",
    "    # Capture user input and code snapshot from widgets\n",
    "    user_input = user_input_widget.value\n",
    "    code_snapshot = code_snapshot_widget.value\n",
    "\n",
    "    # Prepare the variables dictionary as provided\n",
    "    variables = {\n",
    "        \"problem\": problem,\n",
    "        \"time_allotted\": time_allotted,\n",
    "        \"user_input\": user_input,\n",
    "        \"code_snapshot\": code_snapshot,\n",
    "        \"time_elapsed\": time_elapsed,\n",
    "        \"chat_history\": memory.buffer_as_messages\n",
    "    }\n",
    "\n",
    "    # Invoke the AI chain with the provided variables\n",
    "    ai = interview_chain.invoke(variables)\n",
    "    \n",
    "    # Display AI response\n",
    "    clear_output(wait=True)\n",
    "    print(\"Welcome to the DSA Interview Simulator!\")\n",
    "    print(\"AI:\", ai)\n",
    "    \n",
    "    # Update widgets for the next input\n",
    "    user_input_widget.value = ''\n",
    "    code_snapshot_widget.value = ''\n",
    "\n",
    "    # Simulate the memory updates and user input handling\n",
    "    memory.chat_memory.add_ai_message(str(ai))\n",
    "    memory.chat_memory.add_user_message(\n",
    "        user_prompt_template.invoke({\n",
    "            \"user_input\": user_input,\n",
    "            \"code_snapshot\": code_snapshot,\n",
    "            \"time_elapsed\": time_elapsed\n",
    "        }).to_string()\n",
    "    )\n",
    "    \n",
    "    # Increment the iteration counter\n",
    "    i += 1\n",
    "    \n",
    "    # Display the interaction box again for further inputs\n",
    "    display(interaction_box)\n",
    "\n",
    "# Widgets for user input and code snapshot\n",
    "user_input_widget = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter your message...',\n",
    "    description='Message:',\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "code_snapshot_widget = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Paste your code here...',\n",
    "    description='Code:',\n",
    "    layout=widgets.Layout(width='100%', height='200px')\n",
    ")\n",
    "\n",
    "# Submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Attach the button click event to handle_interaction\n",
    "submit_button.on_click(handle_interaction)\n",
    "\n",
    "# Box layout for the interaction UI\n",
    "interaction_box = widgets.VBox([user_input_widget, code_snapshot_widget, submit_button])\n",
    "\n",
    "# Initial UI display\n",
    "clear_output(wait=True)\n",
    "print(\"Welcome to the DSA Interview Simulator!\")\n",
    "\n",
    "display(interaction_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview-it-vA_G3moj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
